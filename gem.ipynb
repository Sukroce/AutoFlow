{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0b3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import joblib\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b48818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Firebase connected.\n",
      "✅ All 3 models and encoders loaded successfully.\n",
      "\n",
      "⏲️ Waiting for 152.43 seconds to align with the next 5-minute mark...\n",
      "\n",
      "--- Running at 2025-12-06 17:35:00 (Index: 211) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating 12 Predictions (Verbose Output) ---\n",
      "Prediction 1 (A): A=252, B=388, C=306\n",
      "Prediction 2 (B): A=251, B=389, C=306\n",
      "Prediction 3 (C): A=253, B=391, C=305\n",
      "Prediction 4 (D): A=255, B=402, C=308\n",
      "Prediction 5 (E): A=254, B=405, C=303\n",
      "Prediction 6 (F): A=253, B=403, C=304\n",
      "Prediction 7 (G): A=258, B=405, C=299\n",
      "Prediction 8 (H): A=259, B=411, C=311\n",
      "Prediction 9 (I): A=256, B=407, C=310\n",
      "Prediction 10 (J): A=254, B=412, C=314\n",
      "Prediction 11 (K): A=257, B=422, C=316\n",
      "Prediction 12 (L): A=258, B=429, C=316\n",
      "\n",
      "--- Updating Firebase Documents A to L ---\n",
      "Updated documents from A to L with predictions for A, B, C.\n",
      "\n",
      "⏲️ Waiting for 278.17 seconds to align with the next 5-minute mark...\n"
     ]
    }
   ],
   "source": [
    "CRED_PATH = 'roads-3moods-firebase-adminsdk-fbsvc-11749dae3d.json' \n",
    "if not firebase_admin._apps:\n",
    "    try:\n",
    "        cred = credentials.Certificate(CRED_PATH)\n",
    "        firebase_admin.initialize_app(cred)\n",
    "        db = firestore.client()\n",
    "        print(\"✅ Firebase connected.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error connecting to Firebase: {e}\")\n",
    "\n",
    "ROADS = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "CAPACITY_A = 338\n",
    "CAPACITY_B = 506\n",
    "CAPACITY_C = 405\n",
    "\n",
    "FACTOR_A = 2 * CAPACITY_A\n",
    "FACTOR_B = 2 * CAPACITY_B\n",
    "FACTOR_C = 2 * CAPACITY_C\n",
    "\n",
    "MODELS = {}\n",
    "ENCODERS = {}\n",
    "\n",
    "try:\n",
    "    MODELS['A'] = joblib.load(f'pkl\\\\july-model-rf.pkl') \n",
    "    ENCODERS['A'] = joblib.load(f'pkl\\\\july-encoder.pkl') \n",
    "\n",
    "    MODELS['B'] = joblib.load(f'pkl\\\\MR-model-rf.pkl') \n",
    "    ENCODERS['B'] = joblib.load(f'pkl\\\\MR-encoder.pkl') \n",
    "\n",
    "    MODELS['C'] = joblib.load(f'pkl\\\\QA-model-rf.pkl') \n",
    "    ENCODERS['C'] = joblib.load(f'pkl\\\\QA-encoder.pkl') \n",
    "\n",
    "    print(\"✅ All 3 models and encoders loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error loading models/encoders: {e}. Ensure 'pkl' directory and files exist.\")\n",
    "\n",
    "A_encoder = ENCODERS['A']\n",
    "B_encoder = ENCODERS['B']\n",
    "C_encoder = ENCODERS['C']\n",
    "\n",
    "A_model = MODELS['A']\n",
    "B_model = MODELS['B']\n",
    "C_model = MODELS['C']\n",
    "\n",
    "def get_document_s_d(doc_id, collection='Ultrasonic_CarCount'):\n",
    "    try:\n",
    "        doc_ref = db.collection(collection).document(doc_id)\n",
    "        doc = doc_ref.get()\n",
    "        return doc.to_dict().get('value') if doc.exists else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching document {doc_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_document(doc_id, collection='Ultrasonic_CarCount'):\n",
    "    try:\n",
    "        doc_ref = db.collection(collection).document(doc_id)\n",
    "        return doc_ref.get()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching document {doc_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_prediction_and_update():\n",
    "    \n",
    "    now = datetime.now()\n",
    "    total_minutes = (now.hour * 60) + now.minute\n",
    "    current_index = total_minutes // 5 \n",
    "    \n",
    "    print(f\"\\n--- Running at {now.strftime('%Y-%m-%d %H:%M:%S')} (Index: {current_index}) ---\")\n",
    "\n",
    "    start_idx = (current_index - 12) % 288\n",
    "    periods_to_fetch = [(start_idx + i) % 288 for i in range(12)]\n",
    "    \n",
    "    sin_time = np.sin(2 * np.pi * current_index / 288)\n",
    "    cos_time = np.cos(2 * np.pi * current_index / 288)\n",
    "\n",
    "    season = get_document_s_d(\"season\")\n",
    "    day = get_document_s_d(\"day\")\n",
    "    \n",
    "    if not all([season, day]):\n",
    "        print(\"❌ Error: Could not fetch season or day data. Skipping prediction.\")\n",
    "        return\n",
    "\n",
    "    As = []\n",
    "    Bs = []\n",
    "    Cs = []\n",
    "    \n",
    "    for cur in periods_to_fetch:\n",
    "        str_cur = str(cur)\n",
    "        doc = get_document(str_cur)\n",
    "        if doc.exists:\n",
    "            data = doc.to_dict()\n",
    "            As.append(data.get('A', 0))\n",
    "            Bs.append(data.get('B', 0))\n",
    "            Cs.append(data.get('C', 0)) \n",
    "        else:\n",
    "            As.append(0)\n",
    "            Bs.append(0)\n",
    "            Cs.append(0)\n",
    "\n",
    "    As_norm = np.array(As) / FACTOR_A\n",
    "    Bs_norm = np.array(Bs) / FACTOR_B\n",
    "    Cs_norm = np.array(Cs) / FACTOR_C\n",
    "    \n",
    "    categoricals = [season, day]\n",
    "    X_categorical = np.array([categoricals]).reshape(1, -1)\n",
    "    encoded = A_encoder.transform(X_categorical) \n",
    "    \n",
    "    numeric_cols = [current_index, sin_time, cos_time]\n",
    "    numeric_cols_2d = np.array(numeric_cols).reshape(1, -1) \n",
    "\n",
    "    predictions_A = [0] * 12\n",
    "    predictions_B = [0] * 12\n",
    "    predictions_C = [0] * 12\n",
    "\n",
    "    predictions_A_norm = [0.0] * 12\n",
    "    predictions_B_norm = [0.0] * 12\n",
    "    predictions_C_norm = [0.0] * 12\n",
    "\n",
    "    As_window = As_norm.tolist()\n",
    "    Bs_window = Bs_norm.tolist()\n",
    "    Cs_window = Cs_norm.tolist()\n",
    "\n",
    "    print(\"\\n--- Generating 12 Predictions (Verbose Output) ---\")\n",
    "\n",
    "    for i in range(12):\n",
    "        if i > 0:\n",
    "            As_window.pop(0) \n",
    "            Bs_window.pop(0) \n",
    "            Cs_window.pop(0) \n",
    "            As_window.append(predictions_A_norm[i-1]) \n",
    "            Bs_window.append(predictions_B_norm[i-1]) \n",
    "            Cs_window.append(predictions_C_norm[i-1]) \n",
    "        \n",
    "        As_2d = np.array(As_window).reshape(1, -1)\n",
    "        Bs_2d = np.array(Bs_window).reshape(1, -1)\n",
    "        Cs_2d = np.array(Cs_window).reshape(1, -1)\n",
    "        \n",
    "        Input_A = np.concatenate([encoded, numeric_cols_2d, As_2d], axis=1)\n",
    "        Input_B = np.concatenate([encoded, numeric_cols_2d, Bs_2d], axis=1)\n",
    "        Input_C = np.concatenate([encoded, numeric_cols_2d, Cs_2d], axis=1) \n",
    "        \n",
    "        prediction_A_norm_val = A_model.predict(Input_A).flatten()[0]\n",
    "        prediction_B_norm_val = B_model.predict(Input_B).flatten()[0]\n",
    "        prediction_C_norm_val = C_model.predict(Input_C).flatten()[0]\n",
    "        \n",
    "        predictions_A_norm[i] = prediction_A_norm_val\n",
    "        predictions_B_norm[i] = prediction_B_norm_val\n",
    "        predictions_C_norm[i] = prediction_C_norm_val\n",
    "        \n",
    "        denorm_A = max(0, int(round(prediction_A_norm_val * FACTOR_A)))\n",
    "        denorm_B = max(0, int(round(prediction_B_norm_val * FACTOR_B)))\n",
    "        denorm_C = max(0, int(round(prediction_C_norm_val * FACTOR_C)))\n",
    "        \n",
    "        print(f\"Prediction {i+1} ({chr(ord('A') + i)}): A={denorm_A}, B={denorm_B}, C={denorm_C}\")\n",
    "\n",
    "    predictions_A_norm_arr = np.array(predictions_A_norm)\n",
    "    predictions_B_norm_arr = np.array(predictions_B_norm)\n",
    "    predictions_C_norm_arr = np.array(predictions_C_norm)\n",
    "\n",
    "    predictions_A_denorm = predictions_A_norm_arr * FACTOR_A\n",
    "    predictions_B_denorm = predictions_B_norm_arr * FACTOR_B\n",
    "    predictions_C_denorm = predictions_C_norm_arr * FACTOR_C\n",
    "\n",
    "    predictions_A = [max(0, int(round(p))) for p in predictions_A_denorm]\n",
    "    predictions_B = [max(0, int(round(p))) for p in predictions_B_denorm]\n",
    "    predictions_C = [max(0, int(round(p))) for p in predictions_C_denorm]\n",
    "    \n",
    "    doc_ids = [chr(ord('A') + i) for i in range(12)]\n",
    "    \n",
    "    print(\"\\n--- Updating Firebase Documents A to L ---\")\n",
    "    \n",
    "    for i, doc_id in enumerate(doc_ids):\n",
    "        update_data = {\n",
    "            'A': predictions_A[i],\n",
    "            'B': predictions_B[i],\n",
    "            'C': predictions_C[i],\n",
    "            'timestamp': firestore.SERVER_TIMESTAMP\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            db.collection('Predictions').document(doc_id).set(update_data, merge=False)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error updating document {doc_id}: {e}\")\n",
    "    print(f\"Updated documents from A to L with predictions for A, B, C.\")\n",
    "\n",
    "def calculate_delay_to_next_period():\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_minutes_total = now.hour * 60 + now.minute\n",
    "    minutes_to_add = 5 - (current_minutes_total % 5)\n",
    "    target_dt = now + timedelta(minutes=minutes_to_add)\n",
    "    target_dt = target_dt.replace(second=0, microsecond=0)\n",
    "    delay_seconds = (target_dt - now).total_seconds()\n",
    "    if (current_minutes_total % 5) == 0 and now.second < 1: \n",
    "        if delay_seconds > 299.9:\n",
    "            return 0\n",
    "    return max(0.0, delay_seconds) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            wait_time = calculate_delay_to_next_period()\n",
    "            \n",
    "            if wait_time > 0:\n",
    "                print(f\"\\n⏲️ Waiting for {wait_time:.2f} seconds to align with the next 5-minute mark...\")\n",
    "                time.sleep(wait_time)\n",
    "            \n",
    "            run_prediction_and_update()\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nScript interrupted by user. Exiting.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn unhandled error occurred in the loop: {e}. Retrying after 5 minutes.\")\n",
    "            time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487dd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
